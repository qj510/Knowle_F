
1、    项目说明：
本项目的主要用途是一键生成知识图谱，在目前，对于知识图谱的生成需要大量的人工参与，并且对于知识图谱的应用范围十分的广泛，包括医疗、教育、金融、政务等领域。而对于这些来说构建一个知识图谱需要大量的人力物力资源，本项目的初衷是利用大模型强大的语义能力，构造知识图谱，不仅减少了人力物力资源的资源消耗，还能够提升知识图谱的可靠性和构建速度。该项目除了需要大模型的api调用以外，只需要使用英特尔cpu进行简单的模型计算，为了方便说明，使用本地英特尔环境进行说明。

2、	项目基本构思
本项目主要运用到千问大模型的信息抽取技术，将用户上传的文档切分成小块发送给大模型，让大模型从中抽取人物、设施、组织等实体，保存为json文件，再进行解析等操作存入mysql数据库，然后使用中文语义计算模型进行知识融合，最后将清洗融合后的知识入图数据库，构造知识图谱

3、	项目运行过程
运行程序的app.py脚本，访问终端域名：http://127.0.0.1:5001
 


从该界面选择本地文档上传，这里为方便演示，选择了小说《斗罗大陆》前三节进行演示
 
在收到前端传来的文档后，程序便会按顺序执行所有脚本，在后台即可观察进度：
知识抽取脚本：
 
解析入库：
 
知识融合，各个实体的计算的相似度也会展示出来：
 
入图数据库，最后在neo4j中即可查看相关知识图谱：
 
4、项目结构
这是本项目的大致结构，modles文件夹下存放的是一个计算中文语义相似度的bert模型。Scripts文件夹下是项目所需要的一系列脚本文件，static下是neovis.js文件，用于neo4j图数据库展示到前端界面，templates存放的是前端界面文件。用户从前端传送的文件会存放到upload目录下，app.py主要作用是除了使用flask进行前端交互，还有就是严格按照顺序运行脚本，每个脚本模块都相互独立，便于调试与修改
 
总共有知识抽取脚本、知识入库脚本、相似度计算脚本、知识融合脚本、数据库转图数据库脚本。
4、	运行要求
 
项目的所有依赖名存放在：依赖.txt
在extract.py中，模型的url换成自己的，我这里使用的是千问110b，模型要求的参数格式为：data {“prompt”:””}
 



需要按装neo4j图数据库。我这里安装的是neo4j desktop1.6.0版本
 

在相似度计算脚步本中一半会优先使用gpu，如果没有gpu就会使用cpu进行运算。在运行程序前尽量删掉脚本生成的一些相关文件，为了方便调试，我保留了脚本生成文件的功能。
对于配置文件confid.json，注意模型的配置文件要配置本地存放中文相似度计算模型的地址，我配置的是我c盘中的模型地址，为了方便我将模型的源文件存放在了项目根目录中，可自行使用。
 
对于config.py配置的是图数据库和mysql 的地址，需要自行根据自己配置。
